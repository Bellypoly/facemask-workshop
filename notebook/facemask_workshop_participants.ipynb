{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning with Face Mask Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data pre-processing \n",
    "### 2. Exploratory data analysis\n",
    "### 3. Image Augmentation\n",
    "### 4. Transfer learning and model building with Keras\n",
    "### 5. Analysis and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install imutils\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (Data Pre-processing) Creating training and testing image arrays and label arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting image path of each image in the training data set:\n",
    "\n",
    "train_data_folder = Path(\"data/train\")\n",
    "\n",
    "train_csv_df = pd.DataFrame(pd.read_csv(\"data/train.csv\"))\n",
    "train_csv_df.head()\n",
    "for i in train_csv_df:\n",
    "    train_csv_df['filepath'] = train_data_folder / train_csv_df['filename']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all images into arrays and loading them into an array or arrays:\n",
    "\n",
    "train_images_array = []\n",
    "for i in range(1178):\n",
    "    z= image.load_img(train_csv_df[\"filepath\"][i],target_size=(300,300))\n",
    "    r = image.img_to_array(z)\n",
    "    r = preprocess_input(r)\n",
    "    train_images_array.append(r)\n",
    "\n",
    "train_images_array = np.array(train_images_array)\n",
    "\n",
    "\n",
    "# making array of training data labels:\n",
    "train_labels = []\n",
    "for row in range(1178):\n",
    "    if train_csv_df[\"class\"][row] == 'with_mask':\n",
    "        y= [1.0, 0.0]\n",
    "    else:\n",
    "        y=[0.0, 1.0]\n",
    "    \n",
    "    train_labels.append(y)\n",
    "\n",
    "    train_labels_array = np.array(train_labels,dtype=\"float32\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing dataset \n",
    "# (doing the same thing that we did for the training dataset)\n",
    "\n",
    "test_data_folder = Path(\"data/test\")\n",
    "\n",
    "test_csv_df = pd.DataFrame(pd.read_csv(\"data/test.csv\"))\n",
    "for i in test_csv_df:\n",
    "    test_csv_df['filepath'] = test_data_folder / test_csv_df['filename']\n",
    "    \n",
    "test_images_array = []\n",
    "for i in range(194):\n",
    "    z= image.load_img(test_csv_df[\"filepath\"][i],target_size=(224,224))\n",
    "    r = image.img_to_array(z)\n",
    "    r = preprocess_input(r) \n",
    "    test_images_array.append(r)\n",
    "\n",
    "test_images_array = np.array(test_images_array)\n",
    "\n",
    "\n",
    "test_labels_array = []\n",
    "for row in range(194):\n",
    "    if test_csv_df[\"class\"][row] == 'with_mask':\n",
    "        y= [1.0, 0.0]\n",
    "    else:\n",
    "        y=[0.0, 1.0]\n",
    "    \n",
    "    test_labels_array.append(y)\n",
    "\n",
    "test_labels_array = np.array(test_labels_array,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Visualizing the numerical form of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory data analysis\n",
    "#### 2.1 Sampling and visually inspecting 20 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling and visually inspecting 20 images:\n",
    "\n",
    "import random\n",
    "for i in random.sample(range(1178), 20):\n",
    "    display(Image.open(train_csv_df['filepath'][i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Checking for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for class imbalance in dataset\n",
    "\n",
    "num_mask= 0\n",
    "num_no_mask = 0\n",
    "\n",
    "labels = [\"Without Mask\", \"With Mask\"]\n",
    "\n",
    "for row in range(1178):\n",
    "    if train_csv_df[\"class\"][row] == 'with_mask':\n",
    "        num_mask +=1\n",
    "    else:\n",
    "        num_no_mask +=1\n",
    "\n",
    "for row in range(194):\n",
    "    if test_csv_df[\"class\"][row] == 'with_mask':\n",
    "        num_mask +=1\n",
    "    else:\n",
    "        num_no_mask +=1\n",
    "\n",
    "num_classes = [num_no_mask, num_mask]\n",
    "     \n",
    "plt.bar(labels, num_classes)\n",
    "plt.title(\"No. of images per class in our dataset\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"No. of images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Visualizing various image augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be visualizing augmentations on the following image:\n",
    "\n",
    "img_to_aug = Path(\"data/train/0-with-mask.jpg\")\n",
    "load_img(img_to_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Horizontal Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data agumentations:\n",
    "# Horizontal shifts\n",
    "\n",
    "img_to_aug = img_to_array(load_img(img_to_aug))\n",
    "img_to_aug = expand_dims(img_to_aug, 0)\n",
    "\n",
    "width_shift = ImageDataGenerator(width_shift_range=[-200,200])\n",
    "\n",
    "it = width_shift.flow(img_to_aug, batch_size=1)\n",
    "\n",
    "for i in range(9):\n",
    "\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    batch = it.next()\n",
    "    image = batch[0].astype('uint8')    \n",
    "    plt.imshow(image)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Horizontal and vertical flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data agumentations:\n",
    "# Horizontal and vertical flips\n",
    "flips = ImageDataGenerator(horizontal_flip=True, \n",
    "                            vertical_flip=True)\n",
    "\n",
    "it = flips.flow(img_to_aug, batch_size=1)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    batch = it.next()\n",
    "    image = batch[0].astype('uint8')\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Random rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data agumentations:\n",
    "# Random rotation\n",
    "\n",
    "rand_rot = ImageDataGenerator(rotation_range=90)\n",
    "\n",
    "it = rand_rot.flow(img_to_aug, batch_size=1)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    batch = it.next()\n",
    "    image = batch[0].astype('uint8')\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Random zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data agumentations:\n",
    "# Random zooming\n",
    "\n",
    "rand_zoom = ImageDataGenerator(zoom_range=[0.5,1.0])\n",
    "\n",
    "it = rand_zoom.flow(img_to_aug, batch_size=1)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    batch = it.next()\n",
    "    image = batch[0].astype('uint8')\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Creating the image augmenter for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Building transfer learning model with Keras\n",
    "\n",
    "##### Adapted from PyImageSearch by Adrian Rosebrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MobileNetV2 network, with the topmost layer removed\n",
    "\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "                        input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "\n",
    "# Freeze the layer of the base model to make them untrainable.\n",
    "# This ensures that their weights are not updated when we train the model.\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "    \n",
    "# Construct head of the model that will be attached on top of the base model:\n",
    "\n",
    "head_model = base_model.output\n",
    "head_model = AveragePooling2D(pool_size=(7, 7))(head_model)\n",
    "head_model = Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(128, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(2, activation=\"softmax\")(head_model)\n",
    "\n",
    "\n",
    "# Combine the head and base of the models together:\n",
    "\n",
    "my_model = Model(inputs=base_model.input, outputs=head_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing initial learning rate, number of epochs to train for, and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compiling the model:\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "my_model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 24s 674ms/step - loss: 0.4682 - accuracy: 0.7478 - val_loss: 0.1172 - val_accuracy: 0.9897\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 23s 643ms/step - loss: 0.4713 - accuracy: 0.7609 - val_loss: 0.1316 - val_accuracy: 0.9897\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 24s 673ms/step - loss: 0.4748 - accuracy: 0.7670 - val_loss: 0.1302 - val_accuracy: 0.9897\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 0.4502 - accuracy: 0.7705 - val_loss: 0.1262 - val_accuracy: 0.9897\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 24s 656ms/step - loss: 0.4547 - accuracy: 0.7696 - val_loss: 0.1174 - val_accuracy: 0.9948\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 24s 671ms/step - loss: 0.4383 - accuracy: 0.7696 - val_loss: 0.1083 - val_accuracy: 0.9948\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 24s 675ms/step - loss: 0.4322 - accuracy: 0.7914 - val_loss: 0.1109 - val_accuracy: 0.9897\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 25s 685ms/step - loss: 0.4470 - accuracy: 0.7723 - val_loss: 0.1128 - val_accuracy: 0.9897\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 24s 679ms/step - loss: 0.4421 - accuracy: 0.7766 - val_loss: 0.1054 - val_accuracy: 0.9948\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 0.4371 - accuracy: 0.7679 - val_loss: 0.1033 - val_accuracy: 0.9948\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 24s 672ms/step - loss: 0.4236 - accuracy: 0.7853 - val_loss: 0.1054 - val_accuracy: 0.9948\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 0.4361 - accuracy: 0.7784 - val_loss: 0.1138 - val_accuracy: 0.9948\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 24s 672ms/step - loss: 0.4434 - accuracy: 0.7792 - val_loss: 0.1218 - val_accuracy: 0.9948\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 0.4258 - accuracy: 0.7769 - val_loss: 0.1034 - val_accuracy: 0.9948\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 25s 687ms/step - loss: 0.4193 - accuracy: 0.7862 - val_loss: 0.1046 - val_accuracy: 0.9948\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 25s 681ms/step - loss: 0.4185 - accuracy: 0.7862 - val_loss: 0.1004 - val_accuracy: 0.9948\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 24s 679ms/step - loss: 0.4181 - accuracy: 0.7897 - val_loss: 0.1012 - val_accuracy: 0.9948\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 25s 681ms/step - loss: 0.4123 - accuracy: 0.7836 - val_loss: 0.0924 - val_accuracy: 0.9897\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 25s 689ms/step - loss: 0.4206 - accuracy: 0.7766 - val_loss: 0.0936 - val_accuracy: 0.9897\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 24s 674ms/step - loss: 0.4272 - accuracy: 0.7888 - val_loss: 0.0971 - val_accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "#### WARNING: DON'T RUN THIS CELL ####\n",
    "#### WARNING: DON'T RUN THIS CELL ####\n",
    "#### WARNING: DON'T RUN THIS CELL ####\n",
    "\n",
    "# Training of the model:\n",
    "# Do not run this cell as training will take long so we will import a model in the next cell\n",
    "# If you wish to train the model, just uncomment the lines below (history = my_model.fit(...))\n",
    "# by selecting the lines and hitting CTRL+/ to uncomment\n",
    "\n",
    "# history = my_model.fit(\n",
    "#     aug.flow(train_images_array, train_labels_array, batch_size=BS),\n",
    "#     steps_per_epoch=len(train_images_array) // BS,\n",
    "#     validation_data=(test_images_array, test_labels_array),\n",
    "#     validation_steps=len(test_images_array)//BS,\n",
    "#     epochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's save our model and training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WARNING: DON'T RUN THIS CELL ####\n",
    "#### WARNING: DON'T RUN THIS CELL ####\n",
    "#### WARNING: DON'T RUN THIS CELL ####\n",
    "\n",
    "# Save our model training history for future analysis\n",
    "\n",
    "# with open(\"./history.pickle\",'wb') as f:\n",
    "#     pickle.dump(history.history, f)\n",
    "\n",
    "# Save our model weights\n",
    "\n",
    "# my_model.save(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model we have given to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "reloaded_model = keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing accuracy of our model using our testing dataset:\n",
    "\n",
    "results = reloaded_model.evaluate(test_images_array, test_labels_array, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *In the above cell, you might have noticed that we have used the validation set as the final evaluation set. This is just for demonstration and ideally, you would use a separate datsest for the final evaluation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analysis and Evaluation:\n",
    "#### Plotting training and validation accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's load the saved training history\n",
    "\n",
    "with open(\"./history.pickle\",'rb') as f:\n",
    "    training_history = pickle.load(f)\n",
    "    \n",
    "# you'd typically instead use history.history[..] instead of training_history[..] but today we've\n",
    "# provided the training_history file for you since training the model and generating the\n",
    "# history takes a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining values of accuracy and loss for training and validation data in each epoch:\n",
    "\n",
    "train_acc = training_history['accuracy']\n",
    "val_acc = training_history['val_accuracy']\n",
    "\n",
    "train_loss = training_history['loss']\n",
    "val_loss = training_history['val_loss']\n",
    "\n",
    "num_epochs = range(len(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting training and validation accuracy graph:\n",
    "\n",
    "plt.plot(num_epochs, train_acc)\n",
    "plt.plot(num_epochs, val_acc)\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
